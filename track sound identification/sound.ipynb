{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXn0WqIEIBQE"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from numpy.random import seed\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MBH5vcQIoy-",
        "outputId": "5807962a-6950-4910-a8e5-cbcbdf353ef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# read_csv加了个header=None，会多读取一行。后续训练要修正一下input shape\n",
        "### 运行一次后自动加载\n",
        "### 1. 两个分类的音频csv自动加载\n",
        "### 2. 合并channel形成4d矩阵后，生成对应label\n",
        "### 3. 构建model，训练model\n",
        "### 4. 存储val_loss最小的model\n",
        "### 5. 初步以0.1为跨度检查哪个区间的阈值，f1 score最高\n",
        "### 6. 在f1 score最高的区间内，再细分1000个刻度进一步检查最合适阈值。\n",
        "### 7. 输出结果\n",
        "### 可选（调用matlab将两个class的音频文件转换为对应矩阵）"
      ],
      "metadata": {
        "id": "PJNOVX2DNd4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def readCsv(fileName):\n",
        "    filePath = f'/content/drive/MyDrive/0819/{fileName}'\n",
        "    folder = pathlib.Path.cwd().parent.joinpath(filePath)\n",
        "    print(folder)\n",
        "    soundMap = dict()  # map[string]list, list elems are np array\n",
        "\n",
        "    for fp in folder.iterdir():\n",
        "        if fp.match('*.csv'):\n",
        "            # 因为有可能名字里带'.'，不能split('.'后取index0. 那就划分完把整个list都取出来，去掉最后index[-1]的csv部分做个拼接)\n",
        "            varname = fp.parts[-1].split('.')\n",
        "            # print(type(varname))\n",
        "            # print(varname)\n",
        "            # if \"ScountRSound_1_7764_0_20220801173146669-3\" in varname[0]:\n",
        "            #   print(type(varname))\n",
        "            #   print(varname)\n",
        "            soundMatrix = pd.read_csv(fp,header=None).values\n",
        "            # print(varname[:-8])  # each file has 4 matrices: Log, Org, Amp, Phs\n",
        "\n",
        "            # ignore the matrices type of sound matrix\n",
        "            varnameList = ','.join(varname[:-1])\n",
        "            # print(varnameList)\n",
        "            soundFileName = varnameList[:-8]\n",
        "            # print(soundFileName)\n",
        "            if soundFileName not in soundMap:\n",
        "                soundMap[soundFileName] = []  \n",
        "            soundMap[soundFileName].append(soundMatrix)\n",
        "            # print(\"type is \", type(soundMatrix))\n",
        "            # print(soundMatrix.shape)\n",
        "    for key in soundMap:\n",
        "      if len(soundMap[key])!=4:\n",
        "        print(key)\n",
        "    return soundMap\n",
        "# readCsv('normal')"
      ],
      "metadata": {
        "id": "0hh8wh9QJHRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get normal and error sound matrix"
      ],
      "metadata": {
        "id": "Q6aePzYseuna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalSound = readCsv('normal')\n",
        "# normalSound['ScountRSound_1_7764_0_20220801173146669-3'].append(pd.read_csv(\"/content/drive/MyDrive/0819/normal/ScountRSound_1_7764_0_20220801173146669-3STFT_Phs.csv\"))\n",
        "normalSoundList = []\n",
        "for v in normalSound.values():\n",
        "    if np.array(v).shape!= (4,38,30):\n",
        "      print(np.array(v).shape)\n",
        "    normalSoundList.append(np.array(v))\n",
        "normalSoundList = np.array(normalSoundList)\n",
        "print(normalSoundList.shape)\n",
        "transposeNormalSoundList = normalSoundList.transpose((0, 2, 3, 1))\n",
        "# transpose of normal sound\n",
        "print(transposeNormalSoundList.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DswB4Ap_N50Q",
        "outputId": "2db93ea7-20bb-4291-eb2b-a0e6f52cccd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/0819/normal\n",
            "(630, 4, 38, 30)\n",
            "(630, 38, 30, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "errorSound = readCsv('error')\n",
        "errSoundList = []\n",
        "for v in errorSound.values():\n",
        "    # print(np.array(v).shape)\n",
        "    errSoundList.append(np.array(v))\n",
        "errSoundList = np.array(errSoundList)\n",
        "transposeErrorSoundList = errSoundList.transpose((0, 2, 3, 1))\n",
        "\n",
        "# transpose of error sound\n",
        "print(transposeErrorSoundList.shape)"
      ],
      "metadata": {
        "id": "oV1ns8VCOB4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d55ea06e-3bf9-49ba-e7f2-ef75b5329ed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/0819/error\n",
            "(570, 38, 30, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seed(123)\n"
      ],
      "metadata": {
        "id": "nVintgKpOFO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get sound labels"
      ],
      "metadata": {
        "id": "PIsiphTBe0ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalLabels = np.ones(len(normalSound), dtype=int)\n",
        "errorLabels = np.zeros(len(errorSound), dtype=int)\n",
        "print(normalLabels.shape)\n",
        "\n",
        "totalLabels = np.concatenate((normalLabels, errorLabels),axis=0)\n",
        "print('len of labels',len(totalLabels))\n",
        "print(totalLabels)\n",
        "\n",
        "totalData = np.concatenate((transposeNormalSoundList, transposeErrorSoundList), axis=0)\n",
        "print(totalData.shape)"
      ],
      "metadata": {
        "id": "Xe31VnBJOHkd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f860e6f-4156-4fbe-892d-8404567ec84e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(630,)\n",
            "len of labels 1200\n",
            "[1 1 1 ... 0 0 0]\n",
            "(1200, 38, 30, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### build model"
      ],
      "metadata": {
        "id": "UwYOeCcBe3zJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(totalData, totalLabels, test_size=0.2, random_state=0)\n",
        "print(y_test)\n",
        "# one-hot\n",
        "y_train = to_categorical(y_train)\n",
        "y_test= to_categorical(y_test)\n",
        "\n",
        "\n",
        "# # separate train and validation set\n",
        "# x, x_test, y, y_test = train_test_split(totalData, totalLabels, test_size=0.2, random_state=0)\n",
        "# print(y_test)\n",
        "# # one-hot\n",
        "# y_train = to_categorical(y_train)\n",
        "# y_test= to_categorical(y_test)\n",
        "# y_test\n",
        "\n",
        "# x_train,x_val,y_train,y_val = train_test_split(x,y,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "NeNDbQ9nrwsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # from keras.constraints import MinMaxNorm\n",
        "# model = models.Sequential()\n",
        "# model.add(layers.Conv2D(32,\n",
        "#                         (3, 3),\n",
        "#                         activation='relu',\n",
        "#                         padding='same',\n",
        "#                         input_shape=(38, 30, 4)))\n",
        "# model.add(layers.Conv2D(32,\n",
        "#                         (3, 3),\n",
        "#                         activation='relu',\n",
        "#                         padding='same',))\n",
        "\n",
        "# model.add(layers.Conv2D(32,\n",
        "#                         (3, 3),\n",
        "#                         activation='relu',\n",
        "#                         padding='same',))\n",
        "# model.add(layers.Conv2D(32,\n",
        "#                         (3, 3),\n",
        "#                         activation='relu',\n",
        "#                         padding='same',))\n",
        "\n",
        "# model.add(layers.Conv2D(32,\n",
        "#                         (3, 3),\n",
        "#                         activation='relu',\n",
        "#                         padding='same',))\n",
        "# model.add(layers.Conv2D(32,\n",
        "#                         (3, 3),\n",
        "#                         activation='relu',\n",
        "#                         padding='same',))\n",
        "\n",
        "# model.add(layers.Dropout(0.1))\n",
        "# model.add(layers.Flatten())\n",
        "# model.add(layers.Dense(32,activation='relu'))\n",
        "# model.add(layers.Dense(2, activation='softmax'))\n",
        "\n",
        "\n",
        "# opt = optimizers.Adam(learning_rate=0.002, decay=1e-6) #0.002， 0.0005\n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer=opt,\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "21xwQPmlONOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import *\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Model\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# def residual_block(layer_input, filters):\n",
        "#     \"\"\"Residual block described in paper\"\"\"\n",
        "#     d = Conv2D(filters, 3, activation='relu', padding='same')(layer_input)\n",
        "#     d = BatchNormalization(momentum=0.8)(d)\n",
        "#     d = Conv2D(filters, 3, activation='relu', padding='same')(d)\n",
        "#     d = BatchNormalization(momentum=0.8)(d)\n",
        "#     d = Add()([d, layer_input])\n",
        "#     return d\n",
        "\n",
        "\n",
        "inputs = Input(shape=(38, 30, 4))\n",
        "conv1 = Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
        "conv2 = Conv2D(32, 3, activation='relu', padding='same')(conv1)\n",
        "conv2 = Conv2D(32, 3, activation='relu', padding='same')(conv2)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "conv3 = Conv2D(32, 3, activation='relu', padding='same')(pool1)\n",
        "conv3 = Conv2D(32, 3, activation='relu', padding='same')(conv3)\n",
        "conv3 = Conv2D(32, 3, activation='relu', padding='same')(conv3)\n",
        "conv3 = Conv2D(32, 3, activation='relu', padding='same')(conv3)\n",
        "\n",
        "D1 = Dropout(0.1)(conv3)\n",
        "D1 = Flatten()(D1)\n",
        "D1 = Dense(32,activation='relu')(D1) #relu\n",
        "Out = Dense(2, activation='softmax')(D1)\n",
        "\n",
        "model = Model(inputs, Out)\n",
        "model.summary()\n",
        "\n",
        "opt = optimizers.Adam(learning_rate=0.0001, decay=1e-6) #0.002， 0.0005\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBDJ6PZ7BJry",
        "outputId": "8eb648d8-5bed-44eb-fb66-b8993fa83596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_38\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_39 (InputLayer)       [(None, 38, 30, 4)]       0         \n",
            "                                                                 \n",
            " conv2d_323 (Conv2D)         (None, 38, 30, 32)        1184      \n",
            "                                                                 \n",
            " conv2d_324 (Conv2D)         (None, 38, 30, 32)        9248      \n",
            "                                                                 \n",
            " conv2d_325 (Conv2D)         (None, 38, 30, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 19, 15, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_326 (Conv2D)         (None, 19, 15, 32)        9248      \n",
            "                                                                 \n",
            " conv2d_327 (Conv2D)         (None, 19, 15, 32)        9248      \n",
            "                                                                 \n",
            " conv2d_328 (Conv2D)         (None, 19, 15, 32)        9248      \n",
            "                                                                 \n",
            " conv2d_329 (Conv2D)         (None, 19, 15, 32)        9248      \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 19, 15, 32)        0         \n",
            "                                                                 \n",
            " flatten_44 (Flatten)        (None, 9120)              0         \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 32)                291872    \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 348,610\n",
            "Trainable params: 348,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "id": "XQe7a7QAdRw7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad6d9456-1b4e-4a36-8ca4-1fe3fb454e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(960, 38, 30, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wJFwDr3-4v99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hUul4ohPBfZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import callbacks\n",
        "callbacks_list = [callbacks.ModelCheckpoint(\n",
        "    filepath = 'best_model-2.h5',\n",
        "    monitor =  'val_loss',\n",
        "    save_best_only = True,\n",
        "    verbose = 1\n",
        ")]\n",
        "\n",
        "history = model.fit(x_train,y_train,epochs=15,batch_size=3,callbacks=callbacks_list,validation_split=0.2)\n"
      ],
      "metadata": {
        "id": "FmCm2AZ9dA9-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c6a8fc-f646-4de5-fe01-08c87d0ec7be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "254/256 [============================>.] - ETA: 0s - loss: 0.7113 - accuracy: 0.5446\n",
            "Epoch 1: val_loss improved from inf to 0.69797, saving model to best_model-2.h5\n",
            "256/256 [==============================] - 3s 7ms/step - loss: 0.7109 - accuracy: 0.5456 - val_loss: 0.6980 - val_accuracy: 0.4844\n",
            "Epoch 2/15\n",
            "253/256 [============================>.] - ETA: 0s - loss: 0.6641 - accuracy: 0.5968\n",
            "Epoch 2: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 0.6640 - accuracy: 0.5977 - val_loss: 0.7866 - val_accuracy: 0.4844\n",
            "Epoch 3/15\n",
            "252/256 [============================>.] - ETA: 0s - loss: 0.6183 - accuracy: 0.6944\n",
            "Epoch 3: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 0.6178 - accuracy: 0.6953 - val_loss: 0.7281 - val_accuracy: 0.4792\n",
            "Epoch 4/15\n",
            "255/256 [============================>.] - ETA: 0s - loss: 0.4877 - accuracy: 0.7895\n",
            "Epoch 4: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 0.4871 - accuracy: 0.7904 - val_loss: 0.7613 - val_accuracy: 0.5104\n",
            "Epoch 5/15\n",
            "255/256 [============================>.] - ETA: 0s - loss: 0.2985 - accuracy: 0.8915\n",
            "Epoch 5: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 0.2982 - accuracy: 0.8919 - val_loss: 0.9019 - val_accuracy: 0.5208\n",
            "Epoch 6/15\n",
            "249/256 [============================>.] - ETA: 0s - loss: 0.1111 - accuracy: 0.9813\n",
            "Epoch 6: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 0.1180 - accuracy: 0.9779 - val_loss: 0.9975 - val_accuracy: 0.5312\n",
            "Epoch 7/15\n",
            "253/256 [============================>.] - ETA: 0s - loss: 0.0547 - accuracy: 0.9921\n",
            "Epoch 7: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 0.0552 - accuracy: 0.9922 - val_loss: 1.2534 - val_accuracy: 0.5469\n",
            "Epoch 8/15\n",
            "254/256 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 1.0000\n",
            "Epoch 8: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 1.4140 - val_accuracy: 0.5208\n",
            "Epoch 9/15\n",
            "250/256 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 1.0000\n",
            "Epoch 9: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 0.0101 - accuracy: 0.9987 - val_loss: 1.5610 - val_accuracy: 0.5312\n",
            "Epoch 10/15\n",
            "253/256 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 1.0000\n",
            "Epoch 10: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.6413 - val_accuracy: 0.5208\n",
            "Epoch 11/15\n",
            "251/256 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 11: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.6149 - val_accuracy: 0.5260\n",
            "Epoch 12/15\n",
            "254/256 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 12: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 7ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8081 - val_accuracy: 0.5156\n",
            "Epoch 13/15\n",
            "252/256 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 13: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.9683 - val_accuracy: 0.5000\n",
            "Epoch 14/15\n",
            "253/256 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 14: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9518 - val_accuracy: 0.5208\n",
            "Epoch 15/15\n",
            "247/256 [===========================>..] - ETA: 0s - loss: 9.0889e-04 - accuracy: 1.0000\n",
            "Epoch 15: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 9.1577e-04 - accuracy: 1.0000 - val_loss: 2.1084 - val_accuracy: 0.5104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss,test_acc = model.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "id": "PI6BG0ZYcSuL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44039808-ba61-4607-bb63-f00cedc86a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1720 - accuracy: 0.5458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('best_model.h5')"
      ],
      "metadata": {
        "id": "0aAVjiyIMalA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "a74d4802-d045-4642-afd3-0c6c66167339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-11eafa4fb841>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[1;32m    425\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[1;32m    426\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n\u001b[0;32m--> 427\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'best_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss,test_acc = model.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "id": "G8eREKgWM-VU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b06f90af-80d2-412d-c019-1f0a768f9378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 5ms/step - loss: 2.2797 - accuracy: 0.5083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc"
      ],
      "metadata": {
        "id": "wUKUOyCTccw4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0745dac9-386d-412c-acbd-f1f0a38b54f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5083333253860474"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss"
      ],
      "metadata": {
        "id": "we6XwQ5hceQP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "4b7ebd3f-5c3d-406b-a421-7de5cbae3077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d48fc8d65a83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_loss' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = model.predict(x_test)"
      ],
      "metadata": {
        "id": "FljCcyFwgI1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "id": "0rukgBmbgQHk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "ab79ba4d-e7ae-415d-bfb3-7e7217cd7535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c08785e04264>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "2bCUubTCF1od",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "427d06ef-07d1-49c7-cd82-549d3a90cd97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.float64(res>0.2)\n",
        "pred"
      ],
      "metadata": {
        "id": "63aaotGLhHr5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33f04401-9967-4171-86c0-ec1d6708861d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "o4r_xwbqln1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target = ['class 0', 'class 1']\n",
        "classification_report(y_test[:,1],pred[:,1])\n"
      ],
      "metadata": {
        "id": "vE7_FvOWl6Ys",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "45c18d71-b488-4a94-895d-072716887e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'              precision    recall  f1-score   support\\n\\n         0.0       0.53      0.40      0.45       126\\n         1.0       0.48      0.61      0.54       114\\n\\n    accuracy                           0.50       240\\n   macro avg       0.51      0.51      0.50       240\\nweighted avg       0.51      0.50      0.49       240\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.int64(res>0.5)\n",
        "y_label = []\n",
        "for v in y_test:\n",
        "  y_label.append(v[0])\n",
        "y_label=np.array(y_label,dtype=int)\n",
        "\n",
        "pred_label = []\n",
        "for v in pred:\n",
        "  pred_label.append(v[0])\n",
        "pred_label=np.array(pred_label,dtype=int)\n",
        "y_label"
      ],
      "metadata": {
        "id": "HgnslciLE6dm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d60cc25-22d3-4d00-bce4-2b0068fdb7b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "       0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "0i3hdbYwpMM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_label"
      ],
      "metadata": {
        "id": "KWfCXsmlShWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "203d4d71-b11a-4322-ca49-99878de5d4f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_label,pred_label)"
      ],
      "metadata": {
        "id": "Sp6l1_HbpMOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2872c9b7-cdc1-489f-dfdc-9b68a102c912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6168831168831169"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred)"
      ],
      "metadata": {
        "id": "16PY0n9gER2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f5dc4d5-ba01-4b10-a0b9-b82def3b6d62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###manual test error data\n"
      ],
      "metadata": {
        "id": "WlTHkZFNMARP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # seed(123)\n",
        "# # test data\n",
        "# testErrorSound = readCsv('tinyError')\n",
        "# print(len(testErrorSound))\n",
        "# testErrorSoundList = []\n",
        "# for v in testErrorSound.values():\n",
        "#     testErrorSoundList.append(np.array(v))\n",
        "# testErrorSoundList = np.array(testErrorSoundList)\n",
        "# transposeTestErrorSoundList = testErrorSoundList.transpose((0, 2, 3, 1))\n",
        "\n",
        "# # transpose of error sound\n",
        "# print(transposeTestErrorSoundList.shape)"
      ],
      "metadata": {
        "id": "G7DtXJ6yMJdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testErrorLabels = np.zeros(len(testErrorSound), dtype=int)\n",
        "# print(testErrorLabels.shape)\n",
        "# testErrorLabels = to_categorical(testErrorLabels)"
      ],
      "metadata": {
        "id": "RsMbuCu_MD3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # test data set\n",
        "# resTest = model.predict(transposeTestErrorSoundList)\n",
        "# predTest = np.int64(resTest>0.5)\n",
        "# test_label = []\n",
        "# for v in testErrorLabels:\n",
        "#   test_label.append(v[0])\n",
        "# test_label=np.array(test_label,dtype=int)\n",
        "\n",
        "# test_pred_label = []\n",
        "# for v in predTest:\n",
        "#   test_pred_label.append(v[0])\n",
        "# test_pred_label=np.array(test_pred_label,dtype=int)"
      ],
      "metadata": {
        "id": "pXwPnDgDI_9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_score = f1_score(test_label,test_pred_label)\n",
        "# test_score"
      ],
      "metadata": {
        "id": "_VnVuGoXLg21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vRange = np.linspace(0.3,0.5,1000)"
      ],
      "metadata": {
        "id": "NhiPAWLkzyQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tuple: (threshold,accuracy)\n",
        "accMap = {\"acc\":(0.0,0.0)}\n",
        "for threshold in vRange:\n",
        "  pred = np.int64(res>threshold)\n",
        "\n",
        "  # get y_label's index0s\n",
        "  y_label = []\n",
        "  for v in y_test:\n",
        "    y_label.append(v[0])\n",
        "  y_label=np.array(y_label,dtype=int)\n",
        "\n",
        "  # get pred_label's index0s\n",
        "  pred_label = []\n",
        "  for v in pred:\n",
        "    pred_label.append(v[0])\n",
        "  pred_label=np.array(pred_label,dtype=int)\n",
        "  score = f1_score(y_label,pred_label)\n",
        "  if score > accMap[\"acc\"][1]:\n",
        "    accMap[\"acc\"] = (threshold,score)\n",
        "accMap[\"acc\"]"
      ],
      "metadata": {
        "id": "gyTWPV3X0Tc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc1d8e3d-254d-440e-8aa9-7e82356267d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.34184184184184185, 0.9655172413793104)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(y_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPsPRXnxIgiC",
        "outputId": "0de1cd68-47b9-44c9-9d11-5a94654e3295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "240\n"
          ]
        }
      ]
    }
  ]
}