{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXn0WqIEIBQE"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from numpy.random import seed\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MBH5vcQIoy-",
        "outputId": "5807962a-6950-4910-a8e5-cbcbdf353ef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# read_csv加了个header=None，会多读取一行。后续训练要修正一下input shape\n",
        "### 运行一次后自动加载\n",
        "### 1. 两个分类的音频csv自动加载\n",
        "### 2. 合并channel形成4d矩阵后，生成对应label\n",
        "### 3. 构建model，训练model\n",
        "### 4. 存储val_loss最小的model\n",
        "### 5. 初步以0.1为跨度检查哪个区间的阈值，f1 score最高\n",
        "### 6. 在f1 score最高的区间内，再细分1000个刻度进一步检查最合适阈值。\n",
        "### 7. 输出结果\n",
        "### 可选（调用matlab将两个class的音频文件转换为对应矩阵）"
      ],
      "metadata": {
        "id": "PJNOVX2DNd4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def readCsv(fileName):\n",
        "    filePath = f'/content/drive/MyDrive/0819/{fileName}'\n",
        "    folder = pathlib.Path.cwd().parent.joinpath(filePath)\n",
        "    print(folder)\n",
        "    soundMap = dict()  # map[string]list, list elems are np array\n",
        "\n",
        "    for fp in folder.iterdir():\n",
        "        if fp.match('*.csv'):\n",
        "            # 因为有可能名字里带'.'，不能split('.'后取index0. 那就划分完把整个list都取出来，去掉最后index[-1]的csv部分做个拼接)\n",
        "            varname = fp.parts[-1].split('.')\n",
        "            # print(type(varname))\n",
        "            # print(varname)\n",
        "            # if \"ScountRSound_1_7764_0_20220801173146669-3\" in varname[0]:\n",
        "            #   print(type(varname))\n",
        "            #   print(varname)\n",
        "            soundMatrix = pd.read_csv(fp,header=None).values\n",
        "            # print(varname[:-8])  # each file has 4 matrices: Log, Org, Amp, Phs\n",
        "\n",
        "            # ignore the matrices type of sound matrix\n",
        "            varnameList = ','.join(varname[:-1])\n",
        "            # print(varnameList)\n",
        "            soundFileName = varnameList[:-8]\n",
        "            # print(soundFileName)\n",
        "            if soundFileName not in soundMap:\n",
        "                soundMap[soundFileName] = []  \n",
        "            soundMap[soundFileName].append(soundMatrix)\n",
        "            # print(\"type is \", type(soundMatrix))\n",
        "            # print(soundMatrix.shape)\n",
        "    for key in soundMap:\n",
        "      if len(soundMap[key])!=4:\n",
        "        print(key)\n",
        "    return soundMap\n",
        "# readCsv('normal')"
      ],
      "metadata": {
        "id": "0hh8wh9QJHRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get normal and error sound matrix"
      ],
      "metadata": {
        "id": "Q6aePzYseuna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalSound = readCsv('normal')\n",
        "# normalSound['ScountRSound_1_7764_0_20220801173146669-3'].append(pd.read_csv(\"/content/drive/MyDrive/0819/normal/ScountRSound_1_7764_0_20220801173146669-3STFT_Phs.csv\"))\n",
        "normalSoundList = []\n",
        "for v in normalSound.values():\n",
        "    if np.array(v).shape!= (4,38,30):\n",
        "      print(np.array(v).shape)\n",
        "    normalSoundList.append(np.array(v))\n",
        "normalSoundList = np.array(normalSoundList)\n",
        "print(normalSoundList.shape)\n",
        "transposeNormalSoundList = normalSoundList.transpose((0, 2, 3, 1))\n",
        "# transpose of normal sound\n",
        "print(transposeNormalSoundList.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DswB4Ap_N50Q",
        "outputId": "2db93ea7-20bb-4291-eb2b-a0e6f52cccd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/0819/normal\n",
            "(630, 4, 38, 30)\n",
            "(630, 38, 30, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "errorSound = readCsv('error')\n",
        "errSoundList = []\n",
        "for v in errorSound.values():\n",
        "    # print(np.array(v).shape)\n",
        "    errSoundList.append(np.array(v))\n",
        "errSoundList = np.array(errSoundList)\n",
        "transposeErrorSoundList = errSoundList.transpose((0, 2, 3, 1))\n",
        "\n",
        "# transpose of error sound\n",
        "print(transposeErrorSoundList.shape)"
      ],
      "metadata": {
        "id": "oV1ns8VCOB4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d55ea06e-3bf9-49ba-e7f2-ef75b5329ed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/0819/error\n",
            "(570, 38, 30, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seed(123)\n"
      ],
      "metadata": {
        "id": "nVintgKpOFO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get sound labels"
      ],
      "metadata": {
        "id": "PIsiphTBe0ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalLabels = np.ones(len(normalSound), dtype=int)\n",
        "errorLabels = np.zeros(len(errorSound), dtype=int)\n",
        "print(normalLabels.shape)\n",
        "\n",
        "totalLabels = np.concatenate((normalLabels, errorLabels),axis=0)\n",
        "print('len of labels',len(totalLabels))\n",
        "print(totalLabels)\n",
        "\n",
        "totalData = np.concatenate((transposeNormalSoundList, transposeErrorSoundList), axis=0)\n",
        "print(totalData.shape)"
      ],
      "metadata": {
        "id": "Xe31VnBJOHkd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f860e6f-4156-4fbe-892d-8404567ec84e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(630,)\n",
            "len of labels 1200\n",
            "[1 1 1 ... 0 0 0]\n",
            "(1200, 38, 30, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### build model"
      ],
      "metadata": {
        "id": "UwYOeCcBe3zJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(totalData, totalLabels, test_size=0.2, random_state=0)\n",
        "print(y_test)\n",
        "# one-hot\n",
        "y_train = to_categorical(y_train)\n",
        "y_test= to_categorical(y_test)\n",
        "\n",
        "\n",
        "# # separate train and validation set\n",
        "# x, x_test, y, y_test = train_test_split(totalData, totalLabels, test_size=0.2, random_state=0)\n",
        "# print(y_test)\n",
        "# # one-hot\n",
        "# y_train = to_categorical(y_train)\n",
        "# y_test= to_categorical(y_test)\n",
        "# y_test\n",
        "\n",
        "# x_train,x_val,y_train,y_val = train_test_split(x,y,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "qbugnDLnOJ0V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "57a00ac5-7e70-41e6-a913-85e6962733c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cd0ab2688c0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotalData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# one-hot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # from keras.constraints import MinMaxNorm\n",
        "# model = models.Sequential()\n",
        "# model.add(layers.Conv2D(32,\n",
        "#                         (3, 3),\n",
        "#                         activation='relu',\n",
        "#                         padding='same',\n",
        "#                         input_shape=(38, 30, 4)))\n",
        "# model.add(layers.Conv2D(32,\n",
        "#                         (3, 3),\n",
        "#                         activation='relu',\n",
        "#                         padding='same',))\n",
        "\n",
        "# model.add(layers.Conv2D(32,\n",
        "#                         (3, 3),\n",
        "#                         activation='relu',\n",
        "#                         padding='same',))\n",
        "# model.add(layers.Conv2D(32,\n",
        "#                         (3, 3),\n",
        "#                         activation='relu',\n",
        "#                         padding='same',))\n",
        "\n",
        "# model.add(layers.Conv2D(32,\n",
        "#                         (3, 3),\n",
        "#                         activation='relu',\n",
        "#                         padding='same',))\n",
        "# model.add(layers.Conv2D(32,\n",
        "#                         (3, 3),\n",
        "#                         activation='relu',\n",
        "#                         padding='same',))\n",
        "\n",
        "# model.add(layers.Dropout(0.1))\n",
        "# model.add(layers.Flatten())\n",
        "# model.add(layers.Dense(32,activation='relu'))\n",
        "# model.add(layers.Dense(2, activation='softmax'))\n",
        "\n",
        "\n",
        "# opt = optimizers.Adam(learning_rate=0.002, decay=1e-6) #0.002， 0.0005\n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer=opt,\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "21xwQPmlONOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import *\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Model\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# def residual_block(layer_input, filters):\n",
        "#     \"\"\"Residual block described in paper\"\"\"\n",
        "#     d = Conv2D(filters, 3, activation='relu', padding='same')(layer_input)\n",
        "#     d = BatchNormalization(momentum=0.8)(d)\n",
        "#     d = Conv2D(filters, 3, activation='relu', padding='same')(d)\n",
        "#     d = BatchNormalization(momentum=0.8)(d)\n",
        "#     d = Add()([d, layer_input])\n",
        "#     return d\n",
        "\n",
        "\n",
        "inputs = Input(shape=(38, 30, 4))\n",
        "conv1 = Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
        "conv2 = Conv2D(32, 3, activation='relu', padding='same')(conv1)\n",
        "conv2 = Conv2D(32, 3, activation='relu', padding='same')(conv2)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "conv3 = Conv2D(32, 3, activation='relu', padding='same')(pool1)\n",
        "conv3 = Conv2D(32, 3, activation='relu', padding='same')(conv3)\n",
        "conv3 = Conv2D(32, 3, activation='relu', padding='same')(conv3)\n",
        "conv3 = Conv2D(32, 3, activation='relu', padding='same')(conv3)\n",
        "\n",
        "D1 = Dropout(0.1)(conv3)\n",
        "D1 = Flatten()(D1)\n",
        "D1 = Dense(32,activation='relu')(D1) #relu\n",
        "Out = Dense(2, activation='softmax')(D1)\n",
        "\n",
        "model = Model(inputs, Out)\n",
        "model.summary()\n",
        "\n",
        "opt = optimizers.Adam(learning_rate=0.0001, decay=1e-6) #0.002， 0.0005\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBDJ6PZ7BJry",
        "outputId": "8eb648d8-5bed-44eb-fb66-b8993fa83596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_38\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_39 (InputLayer)       [(None, 38, 30, 4)]       0         \n",
            "                                                                 \n",
            " conv2d_323 (Conv2D)         (None, 38, 30, 32)        1184      \n",
            "                                                                 \n",
            " conv2d_324 (Conv2D)         (None, 38, 30, 32)        9248      \n",
            "                                                                 \n",
            " conv2d_325 (Conv2D)         (None, 38, 30, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 19, 15, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_326 (Conv2D)         (None, 19, 15, 32)        9248      \n",
            "                                                                 \n",
            " conv2d_327 (Conv2D)         (None, 19, 15, 32)        9248      \n",
            "                                                                 \n",
            " conv2d_328 (Conv2D)         (None, 19, 15, 32)        9248      \n",
            "                                                                 \n",
            " conv2d_329 (Conv2D)         (None, 19, 15, 32)        9248      \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 19, 15, 32)        0         \n",
            "                                                                 \n",
            " flatten_44 (Flatten)        (None, 9120)              0         \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 32)                291872    \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 348,610\n",
            "Trainable params: 348,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "id": "XQe7a7QAdRw7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad6d9456-1b4e-4a36-8ca4-1fe3fb454e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(960, 38, 30, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wJFwDr3-4v99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hUul4ohPBfZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import callbacks\n",
        "callbacks_list = [callbacks.ModelCheckpoint(\n",
        "    filepath = 'best_model-2.h5',\n",
        "    monitor =  'val_loss',\n",
        "    save_best_only = True,\n",
        "    verbose = 1\n",
        ")]\n",
        "\n",
        "history = model.fit(x_train,y_train,epochs=15,batch_size=3,callbacks=callbacks_list,validation_split=0.2)\n"
      ],
      "metadata": {
        "id": "FmCm2AZ9dA9-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c6a8fc-f646-4de5-fe01-08c87d0ec7be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "254/256 [============================>.] - ETA: 0s - loss: 0.7113 - accuracy: 0.5446\n",
            "Epoch 1: val_loss improved from inf to 0.69797, saving model to best_model-2.h5\n",
            "256/256 [==============================] - 3s 7ms/step - loss: 0.7109 - accuracy: 0.5456 - val_loss: 0.6980 - val_accuracy: 0.4844\n",
            "Epoch 2/15\n",
            "253/256 [============================>.] - ETA: 0s - loss: 0.6641 - accuracy: 0.5968\n",
            "Epoch 2: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 0.6640 - accuracy: 0.5977 - val_loss: 0.7866 - val_accuracy: 0.4844\n",
            "Epoch 3/15\n",
            "252/256 [============================>.] - ETA: 0s - loss: 0.6183 - accuracy: 0.6944\n",
            "Epoch 3: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 0.6178 - accuracy: 0.6953 - val_loss: 0.7281 - val_accuracy: 0.4792\n",
            "Epoch 4/15\n",
            "255/256 [============================>.] - ETA: 0s - loss: 0.4877 - accuracy: 0.7895\n",
            "Epoch 4: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 0.4871 - accuracy: 0.7904 - val_loss: 0.7613 - val_accuracy: 0.5104\n",
            "Epoch 5/15\n",
            "255/256 [============================>.] - ETA: 0s - loss: 0.2985 - accuracy: 0.8915\n",
            "Epoch 5: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 0.2982 - accuracy: 0.8919 - val_loss: 0.9019 - val_accuracy: 0.5208\n",
            "Epoch 6/15\n",
            "249/256 [============================>.] - ETA: 0s - loss: 0.1111 - accuracy: 0.9813\n",
            "Epoch 6: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 0.1180 - accuracy: 0.9779 - val_loss: 0.9975 - val_accuracy: 0.5312\n",
            "Epoch 7/15\n",
            "253/256 [============================>.] - ETA: 0s - loss: 0.0547 - accuracy: 0.9921\n",
            "Epoch 7: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 0.0552 - accuracy: 0.9922 - val_loss: 1.2534 - val_accuracy: 0.5469\n",
            "Epoch 8/15\n",
            "254/256 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 1.0000\n",
            "Epoch 8: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 1.4140 - val_accuracy: 0.5208\n",
            "Epoch 9/15\n",
            "250/256 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 1.0000\n",
            "Epoch 9: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 0.0101 - accuracy: 0.9987 - val_loss: 1.5610 - val_accuracy: 0.5312\n",
            "Epoch 10/15\n",
            "253/256 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 1.0000\n",
            "Epoch 10: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.6413 - val_accuracy: 0.5208\n",
            "Epoch 11/15\n",
            "251/256 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 11: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.6149 - val_accuracy: 0.5260\n",
            "Epoch 12/15\n",
            "254/256 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 12: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 7ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8081 - val_accuracy: 0.5156\n",
            "Epoch 13/15\n",
            "252/256 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 13: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.9683 - val_accuracy: 0.5000\n",
            "Epoch 14/15\n",
            "253/256 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 14: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9518 - val_accuracy: 0.5208\n",
            "Epoch 15/15\n",
            "247/256 [===========================>..] - ETA: 0s - loss: 9.0889e-04 - accuracy: 1.0000\n",
            "Epoch 15: val_loss did not improve from 0.69797\n",
            "256/256 [==============================] - 2s 6ms/step - loss: 9.1577e-04 - accuracy: 1.0000 - val_loss: 2.1084 - val_accuracy: 0.5104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss,test_acc = model.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "id": "PI6BG0ZYcSuL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44039808-ba61-4607-bb63-f00cedc86a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1720 - accuracy: 0.5458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('best_model.h5')"
      ],
      "metadata": {
        "id": "0aAVjiyIMalA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "a74d4802-d045-4642-afd3-0c6c66167339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-11eafa4fb841>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[1;32m    425\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[1;32m    426\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n\u001b[0;32m--> 427\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'best_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss,test_acc = model.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "id": "G8eREKgWM-VU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b06f90af-80d2-412d-c019-1f0a768f9378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 5ms/step - loss: 2.2797 - accuracy: 0.5083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc"
      ],
      "metadata": {
        "id": "wUKUOyCTccw4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0745dac9-386d-412c-acbd-f1f0a38b54f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5083333253860474"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss"
      ],
      "metadata": {
        "id": "we6XwQ5hceQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ff63f78-d2f7-4939-83ec-ee0ea9de7dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.5064799785614014"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = model.predict(x_test)"
      ],
      "metadata": {
        "id": "FljCcyFwgI1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "id": "0rukgBmbgQHk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e1ddb6b-4476-4296-e801-58260ddcfa19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.20374262e-01, 3.79625767e-01],\n",
              "       [9.90978718e-01, 9.02128126e-03],\n",
              "       [1.72427401e-01, 8.27572644e-01],\n",
              "       [9.99624014e-01, 3.75939446e-04],\n",
              "       [1.20573509e-06, 9.99998808e-01],\n",
              "       [9.98185575e-01, 1.81439379e-03],\n",
              "       [9.99928594e-01, 7.14526686e-05],\n",
              "       [9.74102795e-01, 2.58972310e-02],\n",
              "       [1.02784917e-01, 8.97215009e-01],\n",
              "       [9.81646597e-01, 1.83533505e-02],\n",
              "       [9.90113378e-01, 9.88656096e-03],\n",
              "       [9.69527304e-01, 3.04727070e-02],\n",
              "       [9.78133500e-01, 2.18664948e-02],\n",
              "       [9.99393106e-01, 6.06844435e-04],\n",
              "       [9.90590453e-01, 9.40954406e-03],\n",
              "       [8.16482544e-01, 1.83517441e-01],\n",
              "       [9.99807060e-01, 1.92961335e-04],\n",
              "       [9.15961802e-01, 8.40381905e-02],\n",
              "       [3.28693569e-01, 6.71306491e-01],\n",
              "       [9.97051477e-01, 2.94846878e-03],\n",
              "       [9.33169305e-01, 6.68306723e-02],\n",
              "       [9.99666691e-01, 3.33289907e-04],\n",
              "       [9.99920487e-01, 7.95334927e-05],\n",
              "       [9.99565899e-01, 4.34136309e-04],\n",
              "       [9.99950171e-01, 4.98381887e-05],\n",
              "       [1.99189693e-01, 8.00810277e-01],\n",
              "       [9.99838233e-01, 1.61718097e-04],\n",
              "       [5.83424978e-03, 9.94165778e-01],\n",
              "       [2.09375992e-01, 7.90624022e-01],\n",
              "       [9.79391276e-04, 9.99020576e-01],\n",
              "       [9.99697804e-01, 3.02282715e-04],\n",
              "       [9.65079725e-01, 3.49203162e-02],\n",
              "       [9.99704063e-01, 2.95931997e-04],\n",
              "       [6.14607513e-01, 3.85392517e-01],\n",
              "       [9.99911427e-01, 8.85914633e-05],\n",
              "       [9.99829173e-01, 1.70771949e-04],\n",
              "       [9.99331117e-01, 6.68879191e-04],\n",
              "       [9.86615181e-01, 1.33847483e-02],\n",
              "       [8.12554419e-01, 1.87445581e-01],\n",
              "       [9.96376336e-01, 3.62360431e-03],\n",
              "       [9.91302371e-01, 8.69762152e-03],\n",
              "       [9.99817669e-01, 1.82379299e-04],\n",
              "       [8.97374868e-01, 1.02625132e-01],\n",
              "       [1.31327251e-04, 9.99868631e-01],\n",
              "       [9.99046624e-01, 9.53369192e-04],\n",
              "       [8.06348212e-03, 9.91936564e-01],\n",
              "       [9.89655256e-01, 1.03447475e-02],\n",
              "       [9.96320724e-01, 3.67922522e-03],\n",
              "       [9.94545579e-01, 5.45438612e-03],\n",
              "       [4.48420644e-01, 5.51579416e-01],\n",
              "       [5.80496490e-02, 9.41950381e-01],\n",
              "       [5.47265969e-02, 9.45273459e-01],\n",
              "       [9.99856472e-01, 1.43484198e-04],\n",
              "       [9.55059975e-02, 9.04493928e-01],\n",
              "       [6.17204118e-04, 9.99382734e-01],\n",
              "       [9.98414516e-01, 1.58543524e-03],\n",
              "       [9.42476034e-01, 5.75239845e-02],\n",
              "       [8.77864063e-01, 1.22135974e-01],\n",
              "       [4.05702800e-01, 5.94297230e-01],\n",
              "       [9.99244809e-01, 7.55217450e-04],\n",
              "       [6.90993309e-01, 3.09006721e-01],\n",
              "       [6.40192270e-01, 3.59807760e-01],\n",
              "       [9.95768905e-01, 4.23112977e-03],\n",
              "       [6.47557735e-01, 3.52442265e-01],\n",
              "       [1.43826904e-03, 9.98561800e-01],\n",
              "       [4.84941512e-01, 5.15058458e-01],\n",
              "       [7.75462687e-01, 2.24537313e-01],\n",
              "       [8.63203466e-01, 1.36796519e-01],\n",
              "       [1.82292459e-03, 9.98177052e-01],\n",
              "       [9.99639988e-01, 3.59956874e-04],\n",
              "       [8.54430377e-01, 1.45569548e-01],\n",
              "       [9.99873996e-01, 1.25969425e-04],\n",
              "       [1.88945636e-01, 8.11054349e-01],\n",
              "       [9.99851227e-01, 1.48754494e-04],\n",
              "       [9.97640133e-01, 2.35984009e-03],\n",
              "       [8.62002969e-01, 1.37996987e-01],\n",
              "       [6.84355080e-01, 3.15644890e-01],\n",
              "       [9.90007997e-01, 9.99196805e-03],\n",
              "       [9.99874473e-01, 1.25552120e-04],\n",
              "       [8.01189959e-01, 1.98810041e-01],\n",
              "       [7.40145385e-01, 2.59854615e-01],\n",
              "       [1.62586793e-02, 9.83741283e-01],\n",
              "       [9.99848962e-01, 1.50990105e-04],\n",
              "       [9.98222053e-01, 1.77792669e-03],\n",
              "       [9.39842761e-01, 6.01572730e-02],\n",
              "       [2.75498658e-01, 7.24501312e-01],\n",
              "       [7.44368657e-02, 9.25563097e-01],\n",
              "       [9.99766290e-01, 2.33713188e-04],\n",
              "       [7.98662826e-02, 9.20133710e-01],\n",
              "       [9.74288106e-01, 2.57118735e-02],\n",
              "       [1.05886914e-01, 8.94113064e-01],\n",
              "       [9.83381867e-01, 1.66181643e-02],\n",
              "       [9.99219179e-01, 7.80776958e-04],\n",
              "       [8.19980085e-01, 1.80019945e-01],\n",
              "       [8.67217958e-01, 1.32782072e-01],\n",
              "       [9.99816477e-01, 1.83494936e-04],\n",
              "       [9.27408037e-05, 9.99907255e-01],\n",
              "       [9.86411393e-01, 1.35886688e-02],\n",
              "       [9.99831915e-01, 1.68047904e-04],\n",
              "       [9.78871524e-01, 2.11284757e-02],\n",
              "       [9.96627212e-01, 3.37278750e-03],\n",
              "       [9.99423504e-01, 5.76484774e-04],\n",
              "       [5.08344114e-01, 4.91655886e-01],\n",
              "       [1.02719188e-01, 8.97280753e-01],\n",
              "       [9.99950290e-01, 4.97452202e-05],\n",
              "       [9.92726564e-01, 7.27347797e-03],\n",
              "       [9.40458119e-01, 5.95418923e-02],\n",
              "       [9.98841703e-01, 1.15838216e-03],\n",
              "       [9.99684691e-01, 3.15309444e-04],\n",
              "       [9.98011231e-01, 1.98872969e-03],\n",
              "       [9.99888778e-01, 1.11245841e-04],\n",
              "       [9.79247570e-01, 2.07524095e-02],\n",
              "       [9.90110338e-01, 9.88964178e-03],\n",
              "       [9.03151870e-01, 9.68481749e-02],\n",
              "       [9.18671787e-01, 8.13282356e-02],\n",
              "       [9.99653816e-01, 3.46150948e-04],\n",
              "       [9.99669433e-01, 3.30565934e-04],\n",
              "       [9.99869585e-01, 1.30438653e-04],\n",
              "       [9.99514699e-01, 4.85354511e-04],\n",
              "       [3.15911055e-01, 6.84088945e-01],\n",
              "       [5.51975131e-01, 4.48024839e-01],\n",
              "       [9.99848366e-01, 1.51599743e-04],\n",
              "       [9.99384165e-01, 6.15870289e-04],\n",
              "       [9.99828577e-01, 1.71424224e-04],\n",
              "       [9.99040186e-01, 9.59798635e-04],\n",
              "       [9.99807537e-01, 1.92514373e-04],\n",
              "       [9.99870777e-01, 1.29234031e-04],\n",
              "       [9.99834418e-01, 1.65557547e-04],\n",
              "       [9.98287976e-01, 1.71201455e-03],\n",
              "       [9.99430597e-01, 5.69327211e-04],\n",
              "       [9.66686070e-01, 3.33139375e-02],\n",
              "       [9.99915719e-01, 8.43146336e-05],\n",
              "       [9.94103968e-01, 5.89603884e-03],\n",
              "       [9.99944210e-01, 5.57400490e-05],\n",
              "       [3.39369684e-01, 6.60630286e-01],\n",
              "       [9.99587953e-01, 4.12051886e-04],\n",
              "       [6.05374277e-01, 3.94625783e-01],\n",
              "       [5.81569271e-03, 9.94184315e-01],\n",
              "       [9.19500053e-01, 8.04999769e-02],\n",
              "       [9.78136510e-02, 9.02186334e-01],\n",
              "       [9.98954296e-01, 1.04573101e-03],\n",
              "       [9.93972361e-01, 6.02765474e-03],\n",
              "       [3.47430825e-01, 6.52569175e-01],\n",
              "       [4.07348365e-01, 5.92651606e-01],\n",
              "       [9.66184139e-01, 3.38158421e-02],\n",
              "       [4.97720634e-07, 9.99999523e-01],\n",
              "       [9.99859571e-01, 1.40435659e-04],\n",
              "       [9.98103619e-01, 1.89634960e-03],\n",
              "       [9.72148597e-01, 2.78514586e-02],\n",
              "       [9.79236305e-01, 2.07637493e-02],\n",
              "       [9.72517908e-01, 2.74821091e-02],\n",
              "       [6.71661556e-01, 3.28338444e-01],\n",
              "       [9.99757111e-01, 2.42856739e-04],\n",
              "       [6.53818846e-01, 3.46181184e-01],\n",
              "       [9.99846220e-01, 1.53765475e-04],\n",
              "       [9.99188006e-01, 8.11943668e-04],\n",
              "       [9.99031186e-01, 9.68841894e-04],\n",
              "       [7.90801227e-01, 2.09198818e-01],\n",
              "       [4.22887802e-01, 5.77112198e-01],\n",
              "       [8.60779226e-01, 1.39220744e-01],\n",
              "       [2.55488932e-01, 7.44511068e-01],\n",
              "       [3.42456304e-04, 9.99657512e-01],\n",
              "       [7.71358967e-01, 2.28641048e-01],\n",
              "       [1.41561369e-03, 9.98584390e-01],\n",
              "       [2.19579106e-05, 9.99978065e-01],\n",
              "       [9.99838352e-01, 1.61675867e-04],\n",
              "       [9.91019189e-01, 8.98080226e-03],\n",
              "       [9.97869611e-01, 2.13032658e-03],\n",
              "       [6.21866345e-01, 3.78133655e-01],\n",
              "       [9.75625694e-01, 2.43743863e-02],\n",
              "       [9.99795735e-01, 2.04265452e-04],\n",
              "       [3.46305072e-02, 9.65369463e-01],\n",
              "       [9.98598635e-01, 1.40138634e-03],\n",
              "       [9.83553410e-01, 1.64465792e-02],\n",
              "       [5.37837744e-01, 4.62162256e-01],\n",
              "       [8.04413736e-01, 1.95586279e-01],\n",
              "       [9.99720871e-01, 2.79165164e-04],\n",
              "       [9.96345937e-01, 3.65404179e-03],\n",
              "       [9.89168644e-01, 1.08313300e-02],\n",
              "       [9.79667544e-01, 2.03324575e-02],\n",
              "       [6.84236065e-02, 9.31576431e-01],\n",
              "       [9.65673506e-01, 3.43264490e-02],\n",
              "       [9.84384179e-01, 1.56158358e-02],\n",
              "       [1.18083186e-01, 8.81916761e-01],\n",
              "       [9.99837518e-01, 1.62447730e-04],\n",
              "       [9.99357879e-01, 6.42083643e-04],\n",
              "       [9.99884486e-01, 1.15538183e-04],\n",
              "       [9.91246641e-01, 8.75335280e-03],\n",
              "       [8.97678971e-01, 1.02320999e-01],\n",
              "       [5.85515022e-01, 4.14484948e-01],\n",
              "       [9.97012019e-01, 2.98799248e-03],\n",
              "       [6.56987607e-01, 3.43012363e-01],\n",
              "       [9.99772012e-01, 2.27999597e-04],\n",
              "       [2.12178454e-01, 7.87821531e-01],\n",
              "       [9.98913288e-01, 1.08673342e-03],\n",
              "       [3.99202645e-06, 9.99996066e-01],\n",
              "       [9.99864340e-01, 1.35653172e-04],\n",
              "       [9.81216729e-01, 1.87832881e-02],\n",
              "       [1.77942449e-03, 9.98220503e-01],\n",
              "       [9.99896169e-01, 1.03795210e-04],\n",
              "       [9.08383075e-03, 9.90916193e-01],\n",
              "       [1.95574539e-04, 9.99804437e-01],\n",
              "       [3.17454785e-01, 6.82545245e-01],\n",
              "       [9.93300796e-01, 6.69920957e-03],\n",
              "       [9.93771613e-01, 6.22839294e-03],\n",
              "       [7.05292761e-01, 2.94707209e-01],\n",
              "       [2.96984874e-02, 9.70301509e-01],\n",
              "       [9.98715162e-01, 1.28482492e-03],\n",
              "       [9.99822557e-01, 1.77512251e-04],\n",
              "       [9.59926769e-02, 9.04007375e-01],\n",
              "       [4.86250974e-05, 9.99951363e-01],\n",
              "       [4.36807703e-03, 9.95631933e-01],\n",
              "       [9.99625325e-01, 3.74600553e-04],\n",
              "       [9.99865413e-01, 1.34620772e-04],\n",
              "       [6.69296787e-05, 9.99933124e-01],\n",
              "       [9.85067010e-01, 1.49330022e-02],\n",
              "       [9.88619089e-01, 1.13808895e-02],\n",
              "       [9.99611795e-01, 3.88222601e-04],\n",
              "       [9.99705017e-01, 2.94936850e-04],\n",
              "       [7.17501447e-04, 9.99282539e-01],\n",
              "       [9.98224318e-01, 1.77572633e-03],\n",
              "       [3.37138736e-05, 9.99966264e-01],\n",
              "       [9.99057114e-01, 9.42884129e-04],\n",
              "       [3.13834459e-01, 6.86165512e-01],\n",
              "       [9.99732316e-01, 2.67683587e-04],\n",
              "       [9.49689269e-01, 5.03107645e-02],\n",
              "       [9.99728262e-01, 2.71751167e-04],\n",
              "       [5.67456782e-01, 4.32543188e-01],\n",
              "       [9.40977454e-01, 5.90225793e-02],\n",
              "       [7.49301672e-01, 2.50698388e-01],\n",
              "       [9.84794796e-01, 1.52052268e-02],\n",
              "       [5.42341135e-02, 9.45765913e-01],\n",
              "       [9.99761641e-01, 2.38343229e-04],\n",
              "       [8.38462353e-01, 1.61537632e-01],\n",
              "       [9.99950528e-01, 4.94765009e-05],\n",
              "       [9.99889851e-01, 1.10078232e-04],\n",
              "       [1.41033530e-02, 9.85896647e-01],\n",
              "       [9.99696016e-01, 3.04056506e-04],\n",
              "       [6.27180457e-01, 3.72819573e-01],\n",
              "       [9.99549568e-01, 4.50448919e-04]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "2bCUubTCF1od",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "427d06ef-07d1-49c7-cd82-549d3a90cd97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.float64(res>0.2)\n",
        "pred"
      ],
      "metadata": {
        "id": "63aaotGLhHr5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33f04401-9967-4171-86c0-ec1d6708861d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "o4r_xwbqln1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target = ['class 0', 'class 1']\n",
        "classification_report(y_test[:,1],pred[:,1])\n"
      ],
      "metadata": {
        "id": "vE7_FvOWl6Ys",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "45c18d71-b488-4a94-895d-072716887e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'              precision    recall  f1-score   support\\n\\n         0.0       0.53      0.40      0.45       126\\n         1.0       0.48      0.61      0.54       114\\n\\n    accuracy                           0.50       240\\n   macro avg       0.51      0.51      0.50       240\\nweighted avg       0.51      0.50      0.49       240\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.int64(res>0.5)\n",
        "y_label = []\n",
        "for v in y_test:\n",
        "  y_label.append(v[0])\n",
        "y_label=np.array(y_label,dtype=int)\n",
        "\n",
        "pred_label = []\n",
        "for v in pred:\n",
        "  pred_label.append(v[0])\n",
        "pred_label=np.array(pred_label,dtype=int)\n",
        "y_label"
      ],
      "metadata": {
        "id": "HgnslciLE6dm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d60cc25-22d3-4d00-bce4-2b0068fdb7b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "       0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "0i3hdbYwpMM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_label"
      ],
      "metadata": {
        "id": "KWfCXsmlShWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "203d4d71-b11a-4322-ca49-99878de5d4f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(y_label,pred_label)"
      ],
      "metadata": {
        "id": "Sp6l1_HbpMOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2872c9b7-cdc1-489f-dfdc-9b68a102c912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6168831168831169"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred)"
      ],
      "metadata": {
        "id": "16PY0n9gER2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f5dc4d5-ba01-4b10-a0b9-b82def3b6d62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###manual test error data\n"
      ],
      "metadata": {
        "id": "WlTHkZFNMARP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # seed(123)\n",
        "# # test data\n",
        "# testErrorSound = readCsv('tinyError')\n",
        "# print(len(testErrorSound))\n",
        "# testErrorSoundList = []\n",
        "# for v in testErrorSound.values():\n",
        "#     testErrorSoundList.append(np.array(v))\n",
        "# testErrorSoundList = np.array(testErrorSoundList)\n",
        "# transposeTestErrorSoundList = testErrorSoundList.transpose((0, 2, 3, 1))\n",
        "\n",
        "# # transpose of error sound\n",
        "# print(transposeTestErrorSoundList.shape)"
      ],
      "metadata": {
        "id": "G7DtXJ6yMJdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testErrorLabels = np.zeros(len(testErrorSound), dtype=int)\n",
        "# print(testErrorLabels.shape)\n",
        "# testErrorLabels = to_categorical(testErrorLabels)"
      ],
      "metadata": {
        "id": "RsMbuCu_MD3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # test data set\n",
        "# resTest = model.predict(transposeTestErrorSoundList)\n",
        "# predTest = np.int64(resTest>0.5)\n",
        "# test_label = []\n",
        "# for v in testErrorLabels:\n",
        "#   test_label.append(v[0])\n",
        "# test_label=np.array(test_label,dtype=int)\n",
        "\n",
        "# test_pred_label = []\n",
        "# for v in predTest:\n",
        "#   test_pred_label.append(v[0])\n",
        "# test_pred_label=np.array(test_pred_label,dtype=int)"
      ],
      "metadata": {
        "id": "pXwPnDgDI_9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_score = f1_score(test_label,test_pred_label)\n",
        "# test_score"
      ],
      "metadata": {
        "id": "_VnVuGoXLg21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vRange = np.linspace(0.3,0.5,1000)"
      ],
      "metadata": {
        "id": "NhiPAWLkzyQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tuple: (threshold,accuracy)\n",
        "accMap = {\"acc\":(0.0,0.0)}\n",
        "for threshold in vRange:\n",
        "  pred = np.int64(res>threshold)\n",
        "\n",
        "  # get y_label's index0s\n",
        "  y_label = []\n",
        "  for v in y_test:\n",
        "    y_label.append(v[0])\n",
        "  y_label=np.array(y_label,dtype=int)\n",
        "\n",
        "  # get pred_label's index0s\n",
        "  pred_label = []\n",
        "  for v in pred:\n",
        "    pred_label.append(v[0])\n",
        "  pred_label=np.array(pred_label,dtype=int)\n",
        "  score = f1_score(y_label,pred_label)\n",
        "  if score > accMap[\"acc\"][1]:\n",
        "    accMap[\"acc\"] = (threshold,score)\n",
        "accMap[\"acc\"]"
      ],
      "metadata": {
        "id": "gyTWPV3X0Tc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc1d8e3d-254d-440e-8aa9-7e82356267d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.34184184184184185, 0.9655172413793104)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(y_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPsPRXnxIgiC",
        "outputId": "0de1cd68-47b9-44c9-9d11-5a94654e3295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "240\n"
          ]
        }
      ]
    }
  ]
}